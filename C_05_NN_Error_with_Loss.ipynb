{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+T/Dyy/FX4Fq5gQE1EzIv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfor21/NN-FROM-SCRATCH-LOW-LEVEL/blob/main/C_05_NN_Error_with_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayuzZw_uLUrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "332f438f-e34b-4075-c81a-c6fa2714dc05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In general, neural network will have two types of activation functions.\\nThe first will be the function used in hidden layers\\nSecond will be used in the output layer.\\nUsually the function used for hidden neurons will be the same for all of them.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''In general, neural network will have two types of activation functions.\n",
        "The first will be the function used in hidden layers\n",
        "Second will be used in the output layer.\n",
        "Usually the function used for hidden neurons will be the same for all of them.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Activation Function"
      ],
      "metadata": {
        "id": "ChQ3U7ZEL3uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Step Activation Function\n",
        "# The Linear Activation Function\n",
        "# The Sigmoid Activation Function\n",
        "# The Rectified Linear Activation Function\n"
      ],
      "metadata": {
        "id": "TEjJVFa2NA-C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPOoAX5pb_pZ",
        "outputId": "57f3a00b-6594-4b4c-b339-8f427b58c4f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnfs) (1.23.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import nnfs\n",
        "nnfs.init()"
      ],
      "metadata": {
        "id": "A3Dci-Vua5OU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nnfs.datasets import spiral_data"
      ],
      "metadata": {
        "id": "dIfNUAxqbvQe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "      self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      self.output = np.dot(inputs, self.weights) + self.biases\n"
      ],
      "metadata": {
        "id": "R-NPTXqkbvVH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReLU Activation Function"
      ],
      "metadata": {
        "id": "yfuqBWwdfjVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward Pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0,inputs)\n"
      ],
      "metadata": {
        "id": "h7C7jfkBbH5H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n"
      ],
      "metadata": {
        "id": "GUk5MOHtbkj_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "# Make a forward pass of our training data through this layer\n",
        "dense1.forward(X)\n"
      ],
      "metadata": {
        "id": "kpUIL1uobkom"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.round(dense1.output[:5],4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntVhtiuoewzN",
        "outputId": "cec7e953-3171-4985-9a27-e80b582186ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.e+00  0.e+00  0.e+00]\n",
            " [-1.e-04  1.e-04 -0.e+00]\n",
            " [-3.e-04  3.e-04 -1.e-04]\n",
            " [-4.e-04  5.e-04 -1.e-04]\n",
            " [-6.e-04  7.e-04 -1.e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass through activation func.\n",
        "# Takes in output from previous layer\n",
        "activation1.forward(dense1.output)\n",
        "print(np.round(activation1.output[:5],8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8xemWs6bkrm",
        "outputId": "a4cd2715-c08c-4f26-8c41-2f6c0b66a83c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.        ]\n",
            " [0.         0.00011395 0.        ]\n",
            " [0.         0.00031729 0.        ]\n",
            " [0.         0.00052666 0.        ]\n",
            " [0.         0.00071401 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Activation Function"
      ],
      "metadata": {
        "id": "ZtnLcSxvffdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAABYCAYAAACu94huAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFxEAABcRAcom8z8AABEHSURBVHhe7Z0HWJRX1sezX2ISs8mXTbJrTVNT9suuNRpJokajMWJJYowao66KvYDYsoqaRBOlWFABsVJUBFEBsaBgARsKoogCikpHikZsgFL8f/dcXnSAYRhgKDOen899mHvfYUR5/+8959xzz30GDMOUgoXBMGpgYTCMGlgYDKMGFgbDqIGFwTBqYGEwjBpYGAyjBhYGw6iBhcEwamBhMIwaWBgMowYWBsOogYVhwOTnFyAwMAjHj59AXn6+HEtISJRfGc2wMAyYkyeD0a5te3RobwQvbx9cunQJO728lauMJlgYBkpySgrmz/8F/gEH4efnBxsrG0yabIYbN28q7wAKCgpw9VossrKylRHNPHjwABkZN5SeYcPCMFDuZ2Xh/v0s+TpH3NBOzq44ciRQ9ou4HHMF/fsPQGRUlDKimb17/eDk4qr0DBsWhoFzJuws9u7bj8jIaGWkOLGxscjNzVV6miGB3bjxZMYxZFgYBszRY8dx/nyE0gOysrORrphCiYlJcHHdJPoZsq8JmlHWrFmLnTu9lBHDh4Whp9y7f1/e+Js3bUaAf4AyWsijR4/g5OQM4169ZVQqNTUdly7HwHHNOqSkXBdP/RvCtHLBwgULYT51mvJd6omPT4Dn9h24eDESPw4egrCzZ5Urhg0LQ88gB1ja+sJnOCx8hoPCud4nTCUHB0dkZt6W74mJicH2HTsRFBiIzVvcMHPGTMyZbYFdvrvl9dTUVCGQFNitssfmzVvkWFmQE08mVHZONoy/7oWIiCczkCHDwtAjsrJzMH7seLRp2Ro3b/6pjBYyZbIptntul68p2qRKfn6enEVUyRLO+dy588VN/1CI7WGp6yUJEAL8olMX3L5dKD5Dh4WhR5DZVO8vz2LD+o3KyBNMRo3BkcNHlF75BAQcgp29A5KTU+Dsskk64CSoAwf8ER1V2lH/7dcFGD9ugtIzfFgYesIj8WfwwMHo0qkzcvPylFHIkOwx4WssXmwpzJ0cZbR8jh0/KZxpH+zatVtGrohbmZno27uv9D1Uodmk/7ffYdVKO2XE8GFh6Am05vB+8/fQr09fLLG2xtIlS6QD7bffH0FCGA8fPlTeqT137twttbiXmpoGb59d8vXdu3dlWsnp0yEw6mCEpKRkOf40wMLQE7y9d6FJg0YI8PdHUmIiksVNStGlbOF36JJTQgRkTmVnZ+OH7wfCd/de6b+sWvX0zBYEC0NPoKhTm1ZtkJ5e/rpDZaFZZ5/fAeFg3xGvc+HouBaWVtbYt89PecfTAwtDT3BxcUUfYf/fuXdPGSlNbFx8udElRjtYGHpCdFQUevU0Rlp6ujJSnPUbNsLdfZvSY6pKpYVx/XoqggKDsHfPXkRGPklCo+dVUnIKP7l0TIFwgof8+BNcSyTxPczNhY/vbjGjFIZcGd1QYWFkCIfPy8sbTuIX4em5Q8bWt2/3goPjGoSeOYutbu5Yv34jC6MaiDgfIW1+v/0HcCbsnFz5PnQ4UKaGlFzUY6pGhYRBM0OXzl2kGEo+nRITEzFu3AT8+6OWCA8/r4wyuoYeOPeEn0FrFrSGkZPzQLnC6BKthUF5ON26dMX8ufOVkdJ4eGxD9y97yPg4w+gzWgvD1XUTOrbv8HjzizpoEcrS0krpMYz+orUwKE3g++/6Kz31pKalwXf3HqXHMPqL1sKYNetntGvdBnfv3VdGSkOLT5S/zzD6jtbCWLd2HV56/gVMnDARISGhuJ6aqlxhGMNDa2HEJySga5cvUP+5emjw2uvo2OETjBszFi7OLsjNK6xZVFtQKgMlvFG0psJNfF9lEvAYw0ZrYRC0LfKX+b/i045GeP1/X8WLzz6Hl194UW55TEmpvRmEcnmMPjFC5886ybRsbVvnzzuhfbv2Mg+JYVSpkDCKSE1Ll4W7yO/o2rkLXnmxPkxGmsgtkLXBrVuZCA09I9uZM2EVaGdwOiQEiUlJyicxTCGVEoYqFL4dOmSomEH+hj179ymjT/Dd5YuNGyq2Eu65bRs83D2UXt0iOTkZU6eYwtzMDNOmmnOr4TZx/HjYr1ql/Daqj3KFQaVTynO0d+7wwl/FrEH+Rkm+6dsPvXv1Rp7KrrPyoE33Y0aPq5NpJbTCbzJiJEaPGoWxJqO51XAbNmQIbKyqf61MozDyCwow12Iurly5qoyoZ//+/Xjj1ddkOciSJAinnRIOKwKFfP+8dUvplU9GRgaOHzuOE8dP4MSJCjTx/qNBR8XfF698EsMUolEYFyOj0P/b/vjzT803qelkUxj3MpaVJ1ShG7YiUP4VlXWpKHFx8djqthXu7u7SBKtIo7yv8PBw5ZPqLpmZmUgTMzeZrjdv3kSCEDNF1ZjqQaMw9uzegzcbN5WOallQGZf2bT+Gn99+ZaSQgIOH8esvv8ktkRRKLY8kYbuvdlwLC4t52CRuVs4WLQ5VLh8+dBjatGyFAd//IDMRLly4qFxldI1GYWxyccVzz/wFEydMKtNHWL7cFjZLlim9Qk4GnxKCsJei6df3G4SEnlGuqCc/Px92dg4yKzctPQP9v/seV65eU64yRaxfuw7/88wz2L59hzLCVBdlCoO2SVrbLMXaNevgtdNL1h46IZ5a586dEy1c3vx0M69YaVdqgYwqV1A2bkhoKIYMGSrNAE1QafnoyzHyNZVy+UaI6WkpHlwRFv2xCK3+1VKYtsWLrTG6p0xhXIuNQ/j5C0qvcMcelYZ0sHfA8mW2OChMpeSU68rV4hRFk2ZMn/m4Op4mVM0mz22emD5jptJjiqD/o8GDBmPCU1T0rDbRaEpVBYpk9e3TD2lp6dJ51/bAEap4Rw4xUxyqWdulUxe5hZWpfqpNGJaLLaWzmJ3zAI5r1yNGCfmeOnUaixdbScGUhKJa333bH2EanP26AG3Emj3rZ0wcNx5z/jtbxtUXCzNHm/bHwt8xd44FzKaYYuTw4RhrYiJeT8Gk8RPkbFwWly5dxqcdP8XlmEKTk6leqk0YRwIDMdpkDFYKP+RiZKQyCjg7u6BRg4aygFhJDh8OlI535u07ykjdhIIFFHF7RjjCrf/dElHR0UhLTRPm5vVyG63RUFGzLVu2Ys7sOejZ4yu8Uv8l6VR/3KYt7t5VH4JdYbsCw4YOR34B76WvCapNGAQVDKabQRVy1OPjE+V5DSVZsmQpBg0YqPTqNlQhfED/Aahf73ksXPC7Mlpx6HPc3Nzw0Yf/RNNGTcqM4I0cMRIWQkjqiItLkEXSGN1RrcIoC1qkik9IlE56Wlra4w39vXsZy1R2fSFamDftWrdFo7//Az67fJXRyhEVfQndu3XHhg2lK5nTLNKjew9s3OikjBQn6OhxrdaK6gJ1Mc1HHTUujMzbt2V5HXLIo6Ki8HG79tjmuR3Lli3HVLOpercDkNJgGr7+Bpq99Y48T7sqUKbAwoWLZIkiVYKCjuLD9z9Qu6Dn6LimTMHUJuHnwmXSn5mpGby9vOW5GlQHlw7N1BbKhCCzlbRU04KqcWFcuxaLkydPydc0/dsK23mhcEjpfDd9eZqoUiB+5pH/GYlnhY8wfNhwZbTy0I2umqVMJf+nmpnjzUaNH6fHUwXyy5evCNPKAs3faYaws+fkeF2BbuZly22lH0bNzHQqhg37j8yOKArN0+96txBKTMwV2VdHSGiYNCGnTJpS41saasWUMjQoNP3ZJ0Z449W/wdvbRxmtHBTxKircTHW8LOZYoGf3r/DlF13x88xZ+H3BAsyfOw9Dh/yElv/3EaaZT5NP1LoECUP1xKdQcYPvK5EyRMydNx8hp0OUXmnyxANgjMloDBn0ozJSc7AwdARlEX/W0QhvN2mKrVvdldGqQYGK25mZj087unPnDm7duiUzCbKFSVIgbsDahH6WkomjqlCOnZu7hzABn0QlCZot6N9SHmR+ff3V19inZp9PdcPC0CFbt3rI3YzN33kXJ04EK6OGh5+fHxYttoSlpTUWi6ZulgwRoli/wUlmAhM5OTliZr0iRbFnnx9++22hzKejhcuyIJ+tdctWuFVOdnd1wMLQIfQEpcjSS889jz7GvQ0uQ5gsNisrG7nHn443Kyh4JAMGkyebFjsD/Oq1a/Lo5AsXI2XOG6UTOaxeAx8fX9m/EBkps4W7fdFNY0bEoj8WY4TwMWrD92Rh6BgKLvQQ4njt5Vewft0GZVT/oY1jY8aMhZmZeSlH2MPDEzOmTZevKSvayclVmlHkV1A9YxOTMdi//4C8TmZhnjABR400wYoVK+VYWQz6YRC2bHFTejULC6MaCAsLw7tvvY0mDRvhaNAxZVS/sRImE63Ql9zURU/zaebTZd1i4t69+8UKfmekZyC9xJkeR48eQ4eP28vZoqydmhTWNRllgsuXY5CQmKiVT6JLWBjVxLp16/HXF15Ezx495c2iz9AmspYf/QsfNG8hz/0jaJGWQq3z5v8iQ7K5udrv6Z85YxYmT5qM2+JmP6RyBDMd1h8sTCwiNi5OFvejw/pX2TsWi3LVBCyMaoJ+kd26fom1a9YWO35YH6EdlfXr1ZOmTUJiktxucDY8Aju9fGSt4or6UuSfUC0w2tagWg/A2cVVmmE0C9Ghm/4H/BFx4SIiIp5sf6gpWBjVABWRmD59BjY6OSsjlSc2Ng4HDx3CwYMHay3tw3zqNFme1XG1o4wu0dkcFan6UhYlBZWXl1/qHEFaE6kNWBjVwBKbpejQrr1Mf6kqx08EY+zYCTIETOZFVaGbOjr6ktwWcO2adtuHydZv0rAxgoRvUF2QGGg1n45prguwMHTMJtfNMP7aWFZF1BV2q+zRtlUb3KnijEHmXWTUJVjbLEHjfzTExYvFF97KgnyIxg0aIjj4tDJSnAcPHyIuPqFK4WkSxo2bN4s57rUJC0OH0HbfTp9+jitXNdfhqgh0s3Xv2g0TJ05SRiqPDJUKE4jWEN5v1hxRUdHKFc3ExFxFi2Yt1G6konUMa+slOHToSDETSN9hYegIsoVHjBgFf/8AZaRykNOpWjyCbO4PWryPTS6lqzxWFlpRrogwCHs7B3xm9Lmsek9QpI0+Z968+fKQTEODhaEjaDfePA3nE2qLsxCAasIdVWhp9va7iLjwJDJDMf0kYYvTRrDklLJbUlKSrNZSEooKVVQYBJXtmT3bAkuFKbbcdhWcnDfJCviGCAujilCuj/lUcwz9adjjrNjKQjcZiauoPA6lXJDj+02fvrJfBIUwPbZ5YocQDaVilNXc3T1w9lzplPTKCoOgxL5CwWkuiaTvsDCqCN2clPNT1QWo1NQ09BUCWL50uTJC5so9ueWVoly6pCrCeFpgYVQBmiFMTc1kykJloXUBWqegQ2wavPF3BAYdVa4UHvZJwggKDFJGdAMLo3xYGJUkMjISX33ZA32Ne8vSmavt7bVq9nZ2sF22HFaWVpj982z0E7PEu2++JdPVjTp8gtsqZ6QHBBzCwAED5cxBGatF/gLlGv3x+yLYWFnDxtqmzEb1bX19d8vvUYWFUT4sjEpAG4gGD/pRJgm+17yF/Nq4gZZNvJcWy5o2aoy3mjSVW1P/+cGH8iuVG1LF1nalEM9/H78m256gr6eCgxFy+jRCQ0LKbMEnT+KqmtAxHS76nhAGZQIz6mFhVAIKzVL93nPh5xF+PkIn7az4vJIRHh+fXRg7ZpzcA+7m5l7l9AhymCkdnEKsr778Cuzs7GUmcMniCwwLo05Di3GUzk17ErKyspXRykPVDFevdhTmnDDrHFbLttJ2BaKj2aQqCQuDYdTAwmAYNbAwGEYNLAyGUQMLg2HUwMJgGDWwMBhGDSwMhlEDC4Nh1MDCYBg1sDAYRg0sDIYpBfD/k9pQmPVQ2pEAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "N6jfIotpvcEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Softmax activation on the output data can take in non-normalized, or uncalibrated, inputs and\n",
        "# produce a normalized distribution of probabilities for our classes."
      ],
      "metadata": {
        "id": "yAgMah5SbkvA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "exp_values = []\n",
        "for output in layer_outputs:\n",
        "  exp_values.append(math.e ** output) # ** - power operator in Python\n",
        "print('exponentiated values:')\n",
        "print(np.round(exp_values,2))"
      ],
      "metadata": {
        "id": "dGajVBKIbkxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc44f3c-8184-4053-bdc0-8b5dba63d22a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exponentiated values:\n",
            "[121.51   3.35  10.86]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now normalize values\n",
        "norm_base = sum(exp_values) # We sum all values\n",
        "norm_values = []\n",
        "for value in exp_values:\n",
        "  norm_values.append(value / norm_base)\n",
        "print('Normalized exponentiated values:')\n",
        "print(np.round(norm_values,2))\n",
        "print('Sum of normalized values:', np.round(sum(norm_values),2))"
      ],
      "metadata": {
        "id": "8A78kaZiLbsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d9ea06-d5e3-4df6-cd68-43fbcc0dcbd6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized exponentiated values:\n",
            "[0.9  0.02 0.08]\n",
            "Sum of normalized values: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### effect of axis parameter"
      ],
      "metadata": {
        "id": "QqircOYd56FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = np.array([[4.8, 1.21, 2.385],\n",
        "[8.9, -1.81, 0.2],\n",
        "[1.41, 1.051, 0.026]])"
      ],
      "metadata": {
        "id": "A-1wbIRtLbvz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(layer_outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u9WV9wZxX9K",
        "outputId": "c3347042-daa5-4bc3-f4c6-e76011764402"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(layer_outputs, axis = None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzca9iIoxYAj",
        "outputId": "e0283a68-a36e-47fd-c206-c4a418fa7a17"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(layer_outputs, axis =0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9qgynXsxYDe",
        "outputId": "bf624402-73bc-4432-bef3-f07a7b05a37f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15.11   0.451  2.611]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(layer_outputs, axis = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1fxH-z2xYHe",
        "outputId": "c4a0a086-6584-42af-e56f-b903a25f4ffe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.395 7.29  2.487]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(layer_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx7XNdXwxYKW",
        "outputId": "d502e3b1-f522-4707-982a-40d0392b6530"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4.8    1.21   2.385]\n",
            " [ 8.9   -1.81   0.2  ]\n",
            " [ 1.41   1.051  0.026]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sum axis 1, but keep the same dimensions as input:')\n",
        "print(np.sum(layer_outputs, axis=1, keepdims=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwYKpsdLxYNq",
        "outputId": "5944e200-bb8d-4628-a2e3-a4ac13b957f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum axis 1, but keep the same dimensions as input:\n",
            "[[8.395]\n",
            " [7.29 ]\n",
            " [2.487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "# Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Get unnormalized probabilities\n",
        "    exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
        "    keepdims=True))\n",
        "  # Normalize them for each sample\n",
        "    probabilities = exp_values / np.sum(exp_values, axis=1,\n",
        "    keepdims=True)\n",
        "    self.output = probabilities"
      ],
      "metadata": {
        "id": "zJ54WBtG7s4x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limitis of exponential function - it explodes easily.\n",
        "# This is the reason of -np.max in the class Softmax.\n",
        "\n",
        "print('exp de 1 =', np.exp(1))\n",
        "print('exp de 10 =', np.exp(10))\n",
        "print('exp de 100 =', np.exp(100))\n",
        "print(np.exp(-np.inf), np.exp(0))\n",
        "\n",
        "# output doesn´t change with a subctration of a constant due to the normalization."
      ],
      "metadata": {
        "id": "Z7oXAf107s8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f967a39-f682-48bd-d23d-51084c1f95b8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exp de 1 = 2.718281828459045\n",
            "exp de 10 = 22026.465794806718\n",
            "exp de 100 = 2.6881171418161356e+43\n",
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values\n",
        "dense2 = Layer_Dense(3, 3)\n",
        "# Create Softmax activation (to be used with Dense layer):\n",
        "activation2 = Activation_Softmax()\n",
        "# Make a forward pass of our training data through this layer\n",
        "dense1.forward(X)\n",
        "# Make a forward pass through activation function\n",
        "# it takes the output of first dense layer here\n",
        "activation1.forward(dense1.output)\n",
        "# Make a forward pass through second Dense layer\n",
        "# it takes outputs of activation function of first layer as inputs\n",
        "dense2.forward(activation1.output)\n",
        "# Make a forward pass through activation function\n",
        "# it takes the output of second dense layer here\n",
        "activation2.forward(dense2.output)"
      ],
      "metadata": {
        "id": "VQ3jqEQg7s_e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(activation2.output[:5])"
      ],
      "metadata": {
        "id": "pfRPS0s97tDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8ce42e-e714-40eb-a389-75e2ca9c46c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33333334 0.33333334 0.33333334]\n",
            " [0.33333334 0.33333334 0.33333334]\n",
            " [0.33333334 0.33333334 0.33333334]\n",
            " [0.33333334 0.33333334 0.33333334]\n",
            " [0.33333334 0.33333334 0.33333334]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqf1Me2v7tGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzDbIFGG7tJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woP2uNsU7tMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}