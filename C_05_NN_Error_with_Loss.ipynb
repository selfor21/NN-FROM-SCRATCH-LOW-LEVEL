{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxAv3/oc+yEnv9z41agVLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfor21/NN-FROM-SCRATCH-LOW-LEVEL/blob/main/C_05_NN_Error_with_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayuzZw_uLUrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "332f438f-e34b-4075-c81a-c6fa2714dc05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In general, neural network will have two types of activation functions.\\nThe first will be the function used in hidden layers\\nSecond will be used in the output layer.\\nUsually the function used for hidden neurons will be the same for all of them.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''            '''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Network Error with Loss"
      ],
      "metadata": {
        "id": "ChQ3U7ZEL3uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Data"
      ],
      "metadata": {
        "id": "RfqliXDCnG9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPOoAX5pb_pZ",
        "outputId": "57f3a00b-6594-4b4c-b339-8f427b58c4f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnfs) (1.23.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import nnfs\n",
        "nnfs.init()"
      ],
      "metadata": {
        "id": "A3Dci-Vua5OU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nnfs.datasets import spiral_data"
      ],
      "metadata": {
        "id": "dIfNUAxqbvQe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n"
      ],
      "metadata": {
        "id": "GUk5MOHtbkj_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes Layer_Dense, ReLU and Softmax Activation Function"
      ],
      "metadata": {
        "id": "k16v9bCenL2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "      self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      self.output = np.dot(inputs, self.weights) + self.biases\n"
      ],
      "metadata": {
        "id": "R-NPTXqkbvVH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward Pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0,inputs)\n"
      ],
      "metadata": {
        "id": "h7C7jfkBbH5H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTR4Tx9qn4Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical Cross-Entropy Loss"
      ],
      "metadata": {
        "id": "ZE-mR4TOnzaH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqf1Me2v7tGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzDbIFGG7tJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woP2uNsU7tMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}