{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNpIJifXfTmC7HmpKQjIfMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfor21/NN-FROM-SCRATCH-LOW-LEVEL/blob/main/UC_04_Activation_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ayuzZw_uLUrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "332f438f-e34b-4075-c81a-c6fa2714dc05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In general, neural network will have two types of activation functions.\\nThe first will be the function used in hidden layers\\nSecond will be used in the output layer.\\nUsually the function used for hidden neurons will be the same for all of them.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''In general, neural network will have two types of activation functions.\n",
        "The first will be the function used in hidden layers\n",
        "Second will be used in the output layer.\n",
        "Usually the function used for hidden neurons will be the same for all of them.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Activation Function"
      ],
      "metadata": {
        "id": "ChQ3U7ZEL3uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Step Activation Function\n",
        "# The Linear Activation Function\n",
        "# The Sigmoid Activation Function\n",
        "# The Rectified Linear Activation Function\n"
      ],
      "metadata": {
        "id": "TEjJVFa2NA-C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPOoAX5pb_pZ",
        "outputId": "01f3ada4-3c5d-489e-f5f0-6347fd2e1a16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnfs) (1.23.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "nnfs.init()"
      ],
      "metadata": {
        "id": "A3Dci-Vua5OU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nnfs.datasets import spiral_data"
      ],
      "metadata": {
        "id": "dIfNUAxqbvQe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "      self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      self.output = np.dot(inputs, self.weights) + self.biases\n"
      ],
      "metadata": {
        "id": "R-NPTXqkbvVH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReLU Activation Function"
      ],
      "metadata": {
        "id": "yfuqBWwdfjVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward Pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0,inputs)\n"
      ],
      "metadata": {
        "id": "h7C7jfkBbH5H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n"
      ],
      "metadata": {
        "id": "GUk5MOHtbkj_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "# Make a forward pass of our training data through this layer\n",
        "dense1.forward(X)\n"
      ],
      "metadata": {
        "id": "kpUIL1uobkom"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.round(dense1.output[:5],4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntVhtiuoewzN",
        "outputId": "99a01a08-4642-4b1a-f603-62b1cb42a5ba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.e+00  0.e+00  0.e+00]\n",
            " [-0.e+00 -1.e-04  0.e+00]\n",
            " [-1.e-04 -2.e-04 -0.e+00]\n",
            " [-2.e-04 -4.e-04 -1.e-04]\n",
            " [-3.e-04 -5.e-04 -2.e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass through activation func.\n",
        "# Takes in output from previous layer\n",
        "activation1.forward(dense1.output)\n",
        "print(np.round(activation1.output[:5],8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8xemWs6bkrm",
        "outputId": "61c91ba9-8325-459f-82e1-267577843ce3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 1.91e-06]\n",
            " [0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Activation Function"
      ],
      "metadata": {
        "id": "ZtnLcSxvffdE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAgMah5SbkvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGajVBKIbkxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8A78kaZiLbsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-1wbIRtLbvz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}